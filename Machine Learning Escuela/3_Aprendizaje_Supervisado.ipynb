{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase 3 Aprendizaje Supervisado\n",
    "Modelo aprende por datos etiquetados. Hace la prediccion basado en patrones observados. Se puede aplicar por ejemplo, en clasificar correos como spam o no.\n",
    "\n",
    "Pasos:\n",
    "- Recolección de datos etiquetados\n",
    "- División de datos (entrenamiento, validación, prueba)\n",
    "- Elección de algortimo\n",
    "- Entrenamiento del modelo\n",
    "- Evaluación y ajuste\n",
    "\n",
    "Tipos de problemas supervisados:\n",
    "- Clasificación como predicción de categorías\n",
    "- Regresión como predicción de valores continuos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Lineal\n",
    "Modela relación entre variable dependiente y una o más independientes. Predice valores continuos basados en Y=mX+b. Y es la variable dependiente, X la independiente, m la pendiente de la línea o coeficiente de regresión y b la intersección con el eje Y o término constante.\n",
    "El objetivo en encontrar m y b para reducir el error cuadrático medio (MSE) entre los valores predichos y los observados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machines)\n",
    "Se emplea tanto en clasificación como regresión. Busca el hiperplano óptimo que separe los datos en diferentes clases con el mayor margen posible.\n",
    "El hiperplano es una línea que divide los datos en clases. SVM maximiza el margen, la distancia entre el hiperplano y los puntos de datos más cercanos de cualquier clase, los vectores de soporte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de decisión\n",
    "Divide iterativamente un conjunto de datos en subconjuntos más pequeños basados en características específicas. Se genera así una estructura jerárquica como de árbol. Tanto para clasificación como regresión.\n",
    "Los nodos son respuestas según características y umbrales establecidos, las ramas son los resultados posibles de una decisión y las hojas las predicciones finales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bosques aleatorios\n",
    "Es un ensamble de múltiples árboles de decisión. Combina la predicción de varios árboles para mejorar la precisión, reducir el sobreajuste y manejar datos más complejos.\n",
    "Múltiples árboles de decisión se entrenan y promedian sus resultados en regresión o uso de voto mayoritario en clasificación. Cada árbol se entrena con un subconjunto aleatorio de datos. Se considera un subconjunto aleatorio de características en cada ramificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes neuronales\n",
    "Capas de nodos interconectados, neuronas, procesan información y aprenden a clasificar, establecer regresiones o determinar patrones complejos.\n",
    "Tienen una capa de entrada que recibe características de los datos, capas ocultas donde son procesados con cálculos y funciones de activación y capa de salida que brinda la predicción. \n",
    "Cada neurona hace un cálculo simple combinando entradas con pesos y aplicando funciones de activación no lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo de Clasificación\n",
    "- Matriz de confusión: tabla con predicciones del modelo frente a clases reales. \n",
    "- Exactitud (Accuracy): proproción de predicciones correctas sobre el total de predicciones. La tasa de errores E es 1-Accuracy\n",
    "- Precisión: proporción de verdaderos positivos entre total de predicciones positivas.\n",
    "- Recall (True Positive Rate) o Sensibilidad: proporción de verdaderos positivos entre total de positivos reales. \n",
    "- F-score o puntuación F1: media armónica de la precisión y el recall. Hay casos donde se prioriza uno sobre otro.\n",
    "- Área Bajo la Curva ROC (AUC-ROC): curva ROC evalúa rendimiento de clasificador binario al variar su umbral de precisión. Eje x es tasa de falsos positivos y eje y es tasa de verdaderos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo de Regresión\n",
    "- R2 score o coeficiente de determinación\n",
    "- Mean Absolute Error (MAE)\n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- Mean Absolute Percentage Error (MAPE)\n",
    "- Error máximo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Técnicas de Validación\n",
    "- Validación cruzada: evalúa capacidad para generalizar a datos no vistos. Dividir conjunto en múltiples subconjuntos, entrenar y validar en diferentes combinaciones de estos pliegues. K-Fold Cross-Validation el conjunto se divide en K partes iguales, el modelo se netrena K veces, cada vez usando K-1 pliegues para el entrenamiento y el restante para la validadción. \n",
    "- División de datos (Entrenamiento, Validación, Prueba): el primero para ajustar parámetros, segundo para ajustar hiperparámetros y seleccionar el mejor modelo y el tercero para evaluar la capacidad de generalización del modelo final. Suele dividirse en 60-20-20.\n",
    "- Ajuste de Hiperparámetros: estas configuraciones que no se aprenden en el entrenamiento, como la profundidad del árbol o la tasa de aprendizaje en las neuronas al ser ajustadas se busca maximizar el rendimiento. Se hace con métodos como Grid Search o búsqueda en cuadrícula que explora todas las combinaciones posibles en un conjunto definido y búsqueda aleatoria o Random Search, selecciona aleatoriamente combinaciones de hiperparámetros en un espacio definido."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
