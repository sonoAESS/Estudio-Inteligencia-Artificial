{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios de laboratorio\n",
    "\n",
    "1) **Preparación y preprocesamiento de datos**\n",
    "\n",
    "        a) Importa un dataset con datos de clasificación o regresión utilizando Pandas. Realiza una exploración inicial de los datos para identificar valores faltantes o anomalías.\n",
    "\n",
    "        b) Imputa o elimina valores nulos, normaliza o estandariza las variables numéricas y divide el conjunto de datos en entrenamiento y prueba (por ejemplo, 80/20).\n",
    "\n",
    "        c) Genera gráficos básicos (histogramas, scatter plots) para comprender la distribución de los datos.\n",
    "\n",
    "2) **Operaciones tensoriales y manipulación con NumPy**\n",
    "\n",
    "    Suma y Broadcasting:\n",
    "\n",
    "        a) Realiza operaciones de suma elemento a elemento entre matrices.\n",
    "\n",
    "        b) Implementa la suma mediante broadcasting entre una matriz y un vector, verificando la \n",
    "        compatibilidad de dimensiones.\n",
    "\n",
    "    Multiplicación y Producto de Hadamard:\n",
    "\n",
    "        a) Realiza la multiplicación matricial considerando las reglas de dimensiones.\n",
    "\n",
    "        b) Implementa el producto de Hadamard, multiplicando elemento a elemento dos matrices de igual dimensión.\n",
    "\n",
    "    Transposición de Tensores:\n",
    "\n",
    "        a) Ejecuta operaciones de transposición en tensores 2D y 3D, documentando cómo se reordenan las dimensiones.\n",
    "\n",
    "3) **Implementación y análisis de funciones de activación**\n",
    "\n",
    "    Función Sigmoide:\n",
    "\n",
    "        a) Implementa la función sigmoide en Python.\n",
    "\n",
    "        b) Grafica su curva y analiza el comportamiento en los extremos (valores altos y bajos).\n",
    "\n",
    "    Función ReLU:\n",
    "\n",
    "        a) Implementa la función ReLU, destacando cómo activa solo entradas positivas.\n",
    "\n",
    "        b) Grafica su función para evidenciar el corte en cero.\n",
    "\n",
    "    Función Tangente Hiperbólica (Tanh):\n",
    "\n",
    "        a) Implementa tanh y compara su salida con la de la sigmoide.\n",
    "\n",
    "        b) Discute las ventajas de tanh para manejar valores negativos.\n",
    "\n",
    "4) **Construcción y propagación de una red neuronal simple**\n",
    "\n",
    "    Definición de la Arquitectura:\n",
    "\n",
    "        a) Define una red neuronal con:\n",
    "\n",
    "        - Capa de entrada adecuada al dataset.\n",
    "        - Una capa oculta con una función de activación (por ejemplo, ReLU o tanh).\n",
    "        - Capa de salida con función sigmoide (para clasificación binaria) o softmax (para clasificación múltiple).\n",
    "\n",
    "    Implementación en Keras:\n",
    "\n",
    "        a) Utiliza la API secuencial de Keras para construir el modelo.\n",
    "\n",
    "        b) Inicializa pesos y sesgos de forma automática y documenta el proceso.\n",
    "\n",
    "    Propagación Hacia Adelante:\n",
    "\n",
    "        a) Realiza la propagación hacia adelante con los datos de entrada, observando la transformación en cada capa.\n",
    "\n",
    "        b) Documenta la salida intermedia de cada capa.\n",
    "\n",
    "5) **Retropropagación, función de pérdida y optimización**\n",
    "\n",
    "    Configuración de la Función de Pérdida:\n",
    "\n",
    "        a) Selecciona una función de pérdida adecuada.\n",
    "\n",
    "        b) Explica brevemente la elección y su impacto en el entrenamiento.\n",
    "\n",
    "    Compilación y Entrenamiento del Modelo:\n",
    "\n",
    "        a) Compila el modelo especificando el optimizador (por ejemplo, Adam) y la función de pérdida.\n",
    "\n",
    "        b) Entrena el modelo en el conjunto de entrenamiento y documenta la evolución de la pérdida durante el entrenamiento.\n",
    "\n",
    "    Evaluación y Retropropagación:\n",
    "\n",
    "        a) Evalúa el modelo en el conjunto de prueba.\n",
    "\n",
    "        b) Analiza cómo la retropropagación ha contribuido a la reducción del error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
